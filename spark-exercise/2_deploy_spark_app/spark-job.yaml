apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: word-count-job
  namespace: default
spec:
  type: Python
  mode: cluster
  image: spark:3.5.3
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "local:///mnt/data/word_count.py" # Reference to the python file
  sparkVersion: 3.5.3
  sparkConf:
    "spark.executor.memory": "1g"
    "spark.driver.memory": "1g"
    "spark.pyspark.python": "python3"
    "spark.pyspark.driver.python": "python3"
    # "spark.kubernetes.driver.label.admission.datadoghq.com/enabled": "true"
    # "spark.kubernetes.executor.label.admission.datadoghq.com/enabled": "true"
    # "spark.kubernetes.driver.annotation.admission.datadoghq.com/java-lib.version": "latest"
    # "spark.kubernetes.executor.annotation.admission.datadoghq.com/java-lib.version": "latest"
    # "spark.driver.extraJavaOptions": "-Ddd.data.jobs.enabled=true -Ddd.service=word-count -Ddd.env=dev -Ddd.version=1.0"
    # "spark.executor.extraJavaOptions": "-Ddd.data.jobs.enabled=true -Ddd.service=word-count -Ddd.env=dev -Ddd.version=1.0"
  driver:
    cores: 1
    memory: "1g"
    serviceAccount: spark-operator-spark
    volumeMounts:
      - name: data-volume
        mountPath: /mnt/data # The local Minikube directory
  executor:
    cores: 1
    memory: "1g"
    instances: 1
    volumeMounts:
      - name: data-volume
        mountPath: /mnt/data # The local Minikube directory
  volumes:
    - name: data-volume
      hostPath:
        path: /mnt/data  # The local Minikube directory
        type: Directory
