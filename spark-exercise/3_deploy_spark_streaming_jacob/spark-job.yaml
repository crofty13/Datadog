apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: real-time-order-processing
  namespace: default
spec:
  type: Python
  mode: cluster
  image: spark:3.5.3-numpy
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "local:///mnt/data/real_time_order_processing.py"
  sparkVersion: 3.5.3
  sparkConf:
    "spark.executor.memory": "1g"
    "spark.driver.memory": "1g"
    "spark.pyspark.python": "python3"
    "spark.pyspark.driver.python": "python3"
    "spark.kubernetes.driver.label.admission.datadoghq.com/enabled": "true"
    "spark.kubernetes.executor.label.admission.datadoghq.com/enabled": "true"
    "spark.kubernetes.driver.annotation.admission.datadoghq.com/java-lib.version": "latest"
    "spark.kubernetes.executor.annotation.admission.datadoghq.com/java-lib.version": "latest"
    "spark.driver.extraJavaOptions": "-Ddd.data.jobs.enabled=true -Ddd.service=real-time-order-processing -Ddd.env=dev -Ddd.version=1.0"
    "spark.executor.extraJavaOptions": "-Ddd.data.jobs.enabled=true -Ddd.service=real-time-order-processing -Ddd.env=dev -Ddd.version=1.0"
  driver:
    cores: 1
    memory: "1g"
    serviceAccount: spark-operator-spark
    volumeMounts:
      - name: data-volume
        mountPath: /mnt/data
  executor:
    cores: 1
    memory: "1g"
    instances: 2
    volumeMounts:
      - name: data-volume
        mountPath: /mnt/data
  volumes:
    - name: data-volume
      hostPath:
        path: /mnt/data  # The local Minikube directory
        type: Directory
